# ShinyApp for PhenomeXcan
These steps read the S-PrediXcan, S-MultiXcan and fastENLOC results and load all the
needed data into a PostgreSQL database for querying from a ShinyApp.


# Configure paths
Open the file `settings.sh` and configure where the different result files are located, as well as the PostgreSQL
connection options. Once that's done, in your terminal type:
```bash
$ . settings.sh
```
In the same terminal follow the steps below. Remember to activate the conda environment for
PhenomeXcan.

Below, the prefix for all paths is `/mnt/phenomexcan_base/`, so remember to adjust it according to
yours.


# Create a new PostgreSQL database
```bash
$ psql -v db_name=${DBDATABASE_NAME} -h ${DBHOST} \
  -U ${DBUSER} -p ${DBPORT} -d postgres \
  -f postgresql/create_database.sql
```

# Create common tables

```bash
# gunzip -k [PHENOMEXCAN_BASE_DIR]/deliverables/phenotypes_info.tsv.gz
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_phenomexcan_phenos.sql
DROP TABLE
CREATE TABLE
COPY 4091
CREATE INDEX

# gunzip -k [PHENOMEXCAN_BASE_DIR]/deliverables/genes_info.tsv.gz
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_genes.sql
DROP TABLE
CREATE TABLE
COPY 22515
CREATE INDEX

$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_tissues.sql
DROP TABLE
CREATE TABLE
COPY 49
CREATE INDEX
```

# S-PrediXcan
1. You should have run the S-PrediXcan results postprocessing with this command:
```bash
$ cd scripts/
$ bash run_nb.sh 100_postprocessing/05_spredixcan.ipynb
```
This will generate a set of HDF5 files for easy reading in the next steps.

1. Run `combine_spredixcan_results.sh` to generate a single `.tsv` file for each tissue with
all the S-PrediXcan results (this will be used later to load into PostgreSQL).
```bash
$ bash combine_spredixcan_results.sh /mnt/tmp/spredixcan_results 12
Output folder: /mnt/tmp/spredixcan_results
Using n jobs: 12
Thyroid - 0
Skin_Not_Sun_Exposed_Suprapubic - 1
Colon_Transverse - 2
Brain_Amygdala - 3
Ovary - 4
Colon_Sigmoid - 5
...
```
where `/mnt/tmp/spredixcan_results` is the output folder and `12` the number of cores/jobs.

1. For the S-PrediXcan results, given the large data, you have to first create the table by running:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_spredixcan.sql
```

1. Then load the data into PostgreSQL with:
```bash
$ cat ${TISSUES_FILE} | cut -f2 | tail -n +2 | \
    parallel -j8 'psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} \
    -c "\copy spredixcan from /mnt/tmp/spredixcan_results/{}.tsv with delimiter as E'"'"'\t'"'"' csv header"'
```
where the file `${TISSUES_FILE}` is generated by the notebook `100_postprocessing/01_genes_mappings.ipynb`.

1. Then create the indexes. This step takes a lot of time, so you can try to parallelize the index
creation in different sessions if possible.
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_spredixcan_indexes.sql
```


# PhenomeXcan and ClinVar
1. Generate the data for PhenomeXcan vs ClinVar by running this command:
```bash
$ bash ../run_nb.sh 10_generate_ukb_clinvar_table.ipynb
```
This notebook will generate a file in `/mnt/phenomexcan_base/gene_assoc/ukb_clinvar.tsv`
(remember that the exact path depends on your configuration).

1. Load the ClinVar traits:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_clinvar_phenos.sql
CREATE TABLE
COPY 5106   
CREATE INDEX
```

1. Create the table for PhenomeXcan vs ClinVar results:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_ukb_clinvar.sql
DROP TABLE  
CREATE TABLE
```

1. Load the data:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} \
    -c "\copy ukb_clinvar from /mnt/phenomexcan_base/gene_assoc/ukb_clinvar.tsv with delimiter as E'\t' csv header"
COPY 20888646
```
where the file `/mnt/phenomexcan_base/gene_assoc/ukb_clinvar.tsv` is generated by the notebook
`10_generate_ukb_clinvar_table.ipynb`.

1. Then create the indexes:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} \
    -f postgresql/load_ukb_clinvar_indexes.sql
```


# S-MultiXcan

1. Generate a file with all results:
```bash
$ bash combine_smultixcan_results.sh /mnt/tmp/output.tsv 4
Output file: /mnt/tmp/output.tsv
Using n jobs: 4
Adding header
Adding data
```
where `/mnt/tmp/output.tsv` is the output file and `4` the number of jobs.

1. Create the SQL table:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_smultixcan.sql
DROP TABLE
CREATE TABLE
```

1. Load the data:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} \
    -c "\copy smultixcan from /mnt/tmp/output.tsv with delimiter as E'\t' csv header"
```

1. Create the SQL indexes:
```bash
$ psql -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} -f postgresql/load_smultixcan_indexes.sql
```


# Database dump

1. Dump the local PostgreSQL database:
```bash
$ pg_dump -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} -d ${DBDATABASE_NAME} \
  --format=plain --no-owner --no-acl \
  | sed -E 's/(DROP|CREATE|COMMENT ON) EXTENSION/-- \1 EXTENSION/g' \
  | gzip > phenomexcan_db.sql.gz
```
You can replace `gzip` with `pigz` for parallel compression.


# Cloud SQL

1. Create a Cloud SQL instance:
```bash
$ export INSTANCE_NAME="phenomexcan-prod-v02"
$ gcloud sql instances create $INSTANCE_NAME \
    --database-version=POSTGRES_11 \
    --tier db-f1-micro \
    --region="us-central1" \
    --storage-auto-increase \
    --availability-type=ZONAL \
    --authorized-networks=54.204.34.9,54.204.36.75,54.204.37.78,34.203.76.245,3.217.214.132,34.197.152.155 \
    --storage-size=100
```

The parameter `--authorized-networks` is for allowing Shinyapp to make queries to Cloud SQL
(IP addresses taken from [here](https://docs.rstudio.com/shinyapps.io/applications.html#firewalls)):

1. Set the password of the `postgres` user:
```bash
$ read -s PASSWORD # enter your password here and then press enter
$ gcloud sql users set-password postgres --instance=$INSTANCE_NAME \
       --password=$PASSWORD
```

1. The next command is necessary to be able to import the data later:
```bash
$ gcloud sql instances patch $INSTANCE_NAME --database-flags temp_file_limit=50971520
```

1. Upload the dump file to a Google Cloud bucket (these steps were taken from the
user guide of Cloud SQL):
```bash
# upload file to google cloud
$ gsutil cp phenomexcan_db.sql.gz gs://phenomexcan/

# get Cloud SQL instance info (serviceAccountEmailAddress)
$ gcloud sql instances describe $INSTANCE_NAME | grep serviceAccountEmailAddress

# add the service account to the bucket ACL as a writer
$ gsutil acl ch -u [SERVICE_ACCOUNT_ADDRESS]:W gs://phenomexcan

# add the service account to the import file as a reader
$ gsutil acl ch -u [SERVICE_ACCOUNT_ADDRESS]:R gs://phenomexcan/phenomexcan_db.sql.gz

# import the data
$ export CLOUD_SQL_DB_NAME="phenomexcan"
$ gcloud sql databases create $CLOUD_SQL_DB_NAME --instance=$INSTANCE_NAME
$ gcloud sql import sql $INSTANCE_NAME \
    gs://phenomexcan/phenomexcan_db.sql.gz \
    --database=${CLOUD_SQL_DB_NAME} \
    --user=postgres
```

1. Create a PostgreSQL read-only user:
```bash
$ read -s USER_READ_ONLY
$ read -s USER_READ_ONLY_PASSWORD
$ gcloud sql users create $USER_READ_ONLY \
   --instance=$INSTANCE_NAME --password=$USER_READ_ONLY_PASSWORD

# within psql as user postgres (superuser)
ALTER ROLE [USER_READ_ONLY] WITH NOCREATEDB NOCREATEROLE;

\c [CLOUD_SQL_DB_NAME]
GRANT CONNECT ON DATABASE [CLOUD_SQL_DB_NAME] TO [USER_READ_ONLY];
GRANT USAGE ON SCHEMA public TO [USER_READ_ONLY];
GRANT SELECT ON clinvar_phenotypes, genes, phenotypes, smultixcan, spredixcan, tissues, ukb_clinvar TO [USER_READ_ONLY];
```

1. Finally, inside a Cloud SQL shell, update the stats of the database so the indexes
are correctly used:
```bash
vacuum analyze;
```


## Shinyapp deploy

Follow the steps described in the
[shinyapp](https://github.com/hakyimlab/phenomexcan/tree/master/scripts/200_webapp/shinyapp) folder.
